#!/usr/bin/python

# Copyright (C) 2013  Stefano Zacchiroli <zack@upsilon.cc>
#
# This file is part of Debsources.
#
# Debsources is free software: you can redistribute it and/or modify it under
# the terms of the GNU Affero General Public License as published by the Free
# Software Foundation, either version 3 of the License, or (at your option) any
# later version.
#
# This program is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
# FOR A PARTICULAR PURPOSE.  See the GNU Affero General Public License for more
# details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import argparse
import atexit
import ConfigParser as configparser
import importlib
import logging
import os
import string
import shutil
import subprocess
import sys

from datetime import datetime
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

BINDIR = os.path.dirname(os.path.abspath(__file__))
ROOTDIR = os.path.dirname(BINDIR)
PLUGINDIR = os.path.join(BINDIR, 'plugins')
PYDIR = os.path.join(ROOTDIR, 'python')
ETCDIR = os.path.join(ROOTDIR, 'etc')
sys.path.insert(0, PYDIR)
sys.path.insert(1, PLUGINDIR)

import dbutils

from debmirror import SourceMirror, SourcePackage
from models import Package, Version, BinaryPackage, BinaryVersion, SuitesMapping

# TODO fill BinaryPackage, BinaryVersion, SuitesMapping

DEFAULT_CONFIG = {
    'dry_run':     'false',
    'passes':      'db fs hooks',
    'log_level':   'info',
    'expire_days': '0',
    'force_triggers': [],
}

LOG_FMT_FILE = '%(asctime)s %(module)s:%(levelname)s %(message)s'
LOG_FMT_STDERR = '%(module)s:%(levelname)s %(message)s'
LOG_DATE_FMT = '%Y-%m-%d %H:%M:%S'

LOG_LEVELS = {	# XXX module logging has no built-in way to do this conversion
                # unless one uses the logging.config cannon. Really?!?
    'debug':    logging.DEBUG,		# verbosity >= 3
    'info':     logging.INFO,		# verbosity >= 2
    'warning':  logging.WARNING,	# verbosity >= 1
    'error':    logging.ERROR,		# verbosity >= 0
    'critical': logging.CRITICAL,
}

KNOWN_EVENTS = [ 'add-package', 'rm-package' ]

# list of per-action observers. Global variable
actions_d = dict( [ (e, []) for e in KNOWN_EVENTS ] )

# DB session maker. Singleton instance
Session = sessionmaker()


def extract_package(pkg, destdir):
    """extract a package to the Debsources file system storage
    """
    logging.debug('extract %s...' % pkg)
    parentdir = os.path.dirname(destdir)
    if not os.path.isdir(parentdir):
        os.makedirs(parentdir)
    if os.path.isdir(destdir):	# remove stale dir, dpkg-source doesn't clobber
        shutil.rmtree(destdir)
    dsc = os.path.join(config['mirror_dir'], pkg.dsc_path())
    cmd = ['dpkg-source', '--no-copy', '--no-check',
           '-x', dsc, destdir ]
    logfile = destdir + '.log'
    donefile = destdir + '.done'
    with open(logfile, 'w') as log:
        subprocess.check_call(cmd, stdout=log, stderr=subprocess.STDOUT)
    open(donefile, 'w').close()


def remove_package(pkg, destdir):
    """dispose of a package from the Debsources file system storage
    """
    if os.path.exists(destdir):
        shutil.rmtree(destdir)
    for meta in ['log', 'done']:
        fname = destdir + '.' + meta
        if os.path.exists(fname):
            os.unlink(fname)
    try:
        os.removedirs(os.path.dirname(destdir))
    except OSError:
        pass	# parent dir is likely non empty, due to other package versions


# TODO get rid of shell hooks; they shall die a horrible death

def notify(event, session, pkg, pkgdir):
    """notify (Python and shell) hooks of occurred events

    Currently supported events:

    * add-package: a package is being added to Debsources; its source files
      have already been unpacked to the file storage and its metadata have
      already been added to the database

    * rm-package: a package is being removed from Debsources; its source files
      are still part of the file storage and its metadata are still part of the
      database

    Python hooks are passed the following arguments, in this order:

    * session: ongoing database session; failures in hook execution will cause
      the session to be rolled back, udoing pending database modifications
      (e.g. the addition/removal of package metadata)

    * pkg: a debmirror.SourcePackage representation of the package being acted
      upon

    * pkgdir: path pointing to the package location in the file storage

    Shell hoks re invoked with the following arguments: pkgdir, package name,
    package version

    """
    logging.debug('notify %s for %s' % (event, pkg))
    package, version = pkg['package'], pkg['version']
    cmd = ['run-parts', '--exit-on-error',
           '--arg', pkgdir,
           '--arg', package,
           '--arg', version,
           os.path.join(config['bin_dir'], event + '.d')
       ]

    # fire shell hooks
    try:
        subprocess.check_output(cmd, stderr=subprocess.STDOUT)
    except subprocess.CalledProcessError, e:
        logging.error('shell hooks for %s on %s returned exit code %d. Output: %s'
                      % (event, pkg, e.returncode, e.output))
        raise e

    notify_plugins(event, session, pkg, pkgdir)


def notify_plugins(event, session, pkg, pkgdir, triggers=None, dry=False):
    """notify Python hooks of occurred events

    If triggers is not None, only Python hooks whose names are listed in them
    will be triggered. Note: shell hooks will not be triggered in that case.
    """
    # fire plugin hooks
    for (title, action) in actions_d[event]:
        try:
            if triggers is None:
                action(session, pkg, pkgdir)
            elif (event, title) in triggers:
                logging.debug('notify (forced) %s/%s for %s' % (event, title, pkg))
                if not dry:
                    action(session, pkg, pkgdir)
        except:
            logging.error('plugin hooks for %s on %s failed' % (event, pkg))
            raise


def load_conffile(conffile):
    """load configuration from file and return it as a (typed) dictionary
    """
    config = configparser.SafeConfigParser(DEFAULT_CONFIG)
    config.read(conffile)

    typed_config = {}
    for (key, value) in config.items('debsources'):
        if key == 'expire_days':
            value = int(value)
        elif key == 'dry_run':
            assert value in ['true', 'false']
            value = (value == 'true')
        elif key == 'hooks':
            value = value.split()
        elif key == 'log_level':
            value = LOG_LEVELS[value]
        elif key == 'passes':
            value = set(value.split())
        typed_config[key] = value
    return typed_config


def load_hooks(conf):
    """load and initialize hooks from the corresponding Python modules
    """
    def subscribe_callback(event, action, title=""):
        if not event in KNOWN_EVENTS:
            raise ValueError('unknown event type "%s"' % event)
        actions_d[event].append((title, action))

    debsources = { 'subscribe': subscribe_callback,
                   'config':    conf }

    for hook in conf['hooks']:
        plugin = importlib.import_module('hook_' + hook)
        plugin.debsources_main(debsources)


def init(conf):
    """startup actions: initialize logging and take mutex lock
    """
    logging.info('start')
    if conf['dry_run']:
        logging.warn('note: DRY RUN mode is enabled')
    if conf['passes'] != set(DEFAULT_CONFIG['passes'].split()):
        logging.warn('only doing passes: %s' % list(conf['passes']))
    if conf['force_triggers']:
        logging.warn('forcing triggers: %s' % conf['force_triggers'])

    lockfile = os.path.join(config['root_dir'], 'ONGOING-UPDATE.pid')
    if os.path.exists(lockfile):
        with open(lockfile) as lock,\
             open(os.devnull, 'w') as null:
            pid = lock.readline().rstrip()
            if subprocess.call(['ps', pid], stdout=null, stderr=null) != 0:
                logging.warn('remove stale lockfile for gone pid %s' % pid)
                os.unlink(lockfile)
            else:
                logging.error('lockfile found. Abort')
                sys.exit(1)
    with open(lockfile, 'w') as lock:
        lock.write('%d\n' % os.getpid())
        atexit.register(lambda: os.unlink(lockfile))


def finish():
    """clean up actions
    """
    # note: lockfile is removed via atexit, no need to do that explicitly here
    logging.info('finish')


def _log_level_of_verbosity(n):
    if n >= 3:
        return logging.DEBUG
    elif n >= 2:
        return logging.INFO
    elif n >= 1:
        return logging.WARNING
    else:
        return logging.ERROR


def update(conf, session):
    """do a full update run
    """
    load_hooks(conf)
    init(conf)
    dry = conf['dry_run']

    # step 1: list mirror and extract new packages
    logging.info('list mirror packages...')
    mirror = SourceMirror(os.path.join(conf['mirror_dir'], 'dists'))
    logging.info('add new packages...')
    for pkg in mirror.ls():
        pkgdir = pkg.extraction_dir(conf['sources_dir'])
        if not dbutils.lookup_version(session, pkg['package'], pkg['version']):
            try:
                logging.info('add %s...' % pkg)
                if not dry and 'fs' in conf['passes']:
                    extract_package(pkg, pkgdir)
                with session.begin_nested():
                    # single db session for package addition and hook
                    # execution: if the hooks fail, the package won't be added
                    # to the db (it will be tried again at next run)
                    if not dry and 'db' in conf['passes']:
                        dbutils.add_package(session, pkg)
                    if not dry and 'hooks' in conf['passes']:
                        notify('add-package', session, pkg, pkgdir)
            except:
                logging.exception('failed to extract %s' % pkg)
        if conf['force_triggers']:
            notify_plugins('add-package', session, pkg, pkgdir,
                           triggers=conf['force_triggers'],
                           dry=dry)

    # step 2: list db and remove disappeared and expired packages
    logging.info('garbage collection...')
    for version in session.query(Version).all():
        pkg = SourcePackage.from_db_model(version)
        pkg_id = (pkg['package'], pkg['version'])
        pkgdir = pkg.extraction_dir(conf['sources_dir'])
        if not pkg_id in mirror.packages:
            # package is in in Debsources db, but gone from mirror: we might
            # have to garbage collect it (depending on expiry)
            try:
                expire_days = config['expire_days']
                age = None
                if os.path.exists(pkgdir):
                    age = datetime.now() \
                          - datetime.fromtimestamp(os.path.getctime(pkgdir))
                if not age or age.days >= expire_days:
                    logging.info("gc %s..." % pkg)
                    if not dry and 'hooks' in conf['passes']:
                        notify('rm-package', session, pkg, pkgdir)
                    if not dry and 'fs' in conf['passes']:
                        remove_package(pkg, pkgdir)
                    if not dry and 'db' in conf['passes']:
                        with session.begin_nested():
                            dbutils.rm_package(session, pkg, version)
                else:
                    logging.debug('not removing %s as it is too young' % pkg)
            except:
                logging.exception('failed to remove %s' % pkg)
        if conf['force_triggers']:
            notify_plugins('rm-package', session, pkg, pkgdir,
                           triggers=conf['force_triggers'],
                           dry=dry)

    finish()


if __name__ == '__main__':
    cmdline = argparse.ArgumentParser(description='Debsources updater')
    cmdline.add_argument('--config', '-c', dest='conffile',
                         help='alternate configuration file')
    cmdline.add_argument('--pass', '-p',
                         metavar='PASS',
                         action='append',
                         help='only perform a specific update pass (one of: db, fs, hooks). By default all passes are enabled; the special value "none" disables all passes. Can be specified multiple times. Warning: you will mess up update logic, use at your own risk.',
                         dest='passes')
    cmdline.add_argument('--trigger', '-t',
                         metavar='EVENT/HOOK',
                         action='append',
                         help='force trigger of (Python) HOOK for EVENT. By default all registered hooks are triggered for all changed packages. Event is one of: %s. Hook is one of the available hooks. Can be specified multiple times. Warning: if not used with "--pass none" it might lead to multiple execution of the same hook. E.g.: -t add-package/checksums' % string.join(KNOWN_EVENTS, ', '),
                         dest='force_triggers')
    cmdline.add_argument('--verbose', '-v',
                         action='count',
                         help='increase console verbosity')
    args = cmdline.parse_args()

    conffile = os.path.join(ETCDIR, 'config.ini')
    alt_conffile = os.path.join(ETCDIR, 'config.local.ini')
    if os.path.exists(alt_conffile):
        conffile = alt_conffile
    if args.conffile:
        conffile = args.conffile
    config = load_conffile(conffile)

    # override configuration from cmdline args
    if args.passes:
        if 'none' in args.passes:
            config['passes'] = set()
        else:
            config['passes'] = set(args.passes)
    if args.force_triggers:
        config['force_triggers'] = []
        for trigger in args.force_triggers:
            (event, hook) = trigger.split('/')
            config['force_triggers'].append((event, hook))

    # Set up logging: log everythong to logfile, log errors to stderr. stderr
    # will be shown on console for interactive use, or mailed by cron.
    logging.basicConfig(level=logging.DEBUG, # log everything by default
                        format=LOG_FMT_FILE,
                        datefmt=LOG_DATE_FMT,
                        filename=config['log_file'])
    logger = logging.getLogger()
    logger.handlers[0].setLevel(config['log_level']) # logfile verbosity
    stderr_log = logging.StreamHandler()
    stderr_log.setLevel(_log_level_of_verbosity(args.verbose)) # console verb.
    stderr_log.setFormatter(logging.Formatter(LOG_FMT_STDERR))
    logger.addHandler(stderr_log)

    logging.debug('loaded configuration from %s' % conffile)

    try:
        db = create_engine(config['db_uri'])
        session = Session(bind=db)
        update(config, session)
        session.commit()
    except SystemExit:	# exit as requested
        raise
    except:	# store trace in log, then exit
        logging.exception('unhandled exception. Abort')
        sys.exit(2)
