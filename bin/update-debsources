#!/usr/bin/python

# Copyright (C) 2013  Stefano Zacchiroli <zack@upsilon.cc>
#
# This file is part of Debsources.
#
# Debsources is free software: you can redistribute it and/or modify it under
# the terms of the GNU Affero General Public License as published by the Free
# Software Foundation, either version 3 of the License, or (at your option) any
# later version.
#
# This program is distributed in the hope that it will be useful, but WITHOUT
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
# FOR A PARTICULAR PURPOSE.  See the GNU Affero General Public License for more
# details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import argparse
import atexit
import logging
import os
import string
import subprocess
import sys

from datetime import datetime
from email.utils import formatdate
from sqlalchemy import create_engine, func as sql_func
from sqlalchemy.orm import sessionmaker

import mainlib
import dbutils
import fs_storage

from debmirror import SourceMirror, SourcePackage
from models import Metric, Version

# TODO fill tables: BinaryPackage, BinaryVersion, SuitesMapping

# list of per-action observers. Global variable
observers = None

# DB session maker. Singleton instance
Session = sessionmaker()


# TODO get rid of shell hooks; they shall die a horrible death

def notify(conf, event, session, pkg, pkgdir):
    """notify (Python and shell) hooks of occurred events

    Currently supported events:

    * add-package: a package is being added to Debsources; its source files
      have already been unpacked to the file storage and its metadata have
      already been added to the database

    * rm-package: a package is being removed from Debsources; its source files
      are still part of the file storage and its metadata are still part of the
      database

    Python hooks are passed the following arguments, in this order:

    * session: ongoing database session; failures in hook execution will cause
      the session to be rolled back, udoing pending database modifications
      (e.g. the addition/removal of package metadata)

    * pkg: a debmirror.SourcePackage representation of the package being acted
      upon

    * pkgdir: path pointing to the package location in the file storage

    Shell hoks re invoked with the following arguments: pkgdir, package name,
    package version

    """
    logging.debug('notify %s for %s' % (event, pkg))
    package, version = pkg['package'], pkg['version']
    cmd = ['run-parts', '--exit-on-error',
           '--arg', pkgdir,
           '--arg', package,
           '--arg', version,
           os.path.join(conf['bin_dir'], event + '.d')
       ]

    # fire shell hooks
    try:
        subprocess.check_output(cmd, stderr=subprocess.STDOUT)
    except subprocess.CalledProcessError, e:
        logging.error('shell hooks for %s on %s returned exit code %d. Output: %s'
                      % (event, pkg, e.returncode, e.output))
        raise e

    notify_plugins(event, session, pkg, pkgdir)


def notify_plugins(event, session, pkg, pkgdir, triggers=None, dry=False):
    """notify Python hooks of occurred events

    If triggers is not None, only Python hooks whose names are listed in them
    will be triggered. Note: shell hooks will not be triggered in that case.
    """
    global observers

    for (title, action) in observers[event]:
        try:
            if triggers is None:
                action(session, pkg, pkgdir)
            elif (event, title) in triggers:
                logging.info('notify (forced) %s/%s for %s' % (event, title, pkg))
                if not dry:
                    action(session, pkg, pkgdir)
        except:
            logging.error('plugin hooks for %s on %s failed' % (event, pkg))
            raise


def init(conf):
    """startup actions: initialize logging and take mutex lock
    """
    logging.info('start')
    if conf['dry_run']:
        logging.warn('note: DRY RUN mode is enabled')
    if conf['passes'] != set(mainlib.DEFAULT_CONFIG['passes'].split()):
        logging.warn('only doing passes: %s' % list(conf['passes']))
    if conf['force_triggers']:
        logging.warn('forcing triggers: %s' % conf['force_triggers'])

    lockfile = os.path.join(conf['root_dir'], 'ONGOING-UPDATE.pid')
    if os.path.exists(lockfile):
        with open(lockfile) as lock,\
             open(os.devnull, 'w') as null:
            pid = lock.readline().rstrip()
            if subprocess.call(['ps', pid], stdout=null, stderr=null) != 0:
                logging.warn('remove stale lockfile for gone pid %s' % pid)
                os.unlink(lockfile)
            else:
                logging.error('lockfile found. Abort')
                sys.exit(1)
    with open(lockfile, 'w') as lock:
        lock.write('%d\n' % os.getpid())
        atexit.register(lambda: os.unlink(lockfile))


def update_metadata(conf, session):
    # update global stats file (most notably: size info in it)
    stats_file = os.path.join(conf['cache_dir'], 'stats.data')
    total_size = session.query(sql_func.sum(Metric.value)) \
                        .filter_by(metric='size').first()
    with open(stats_file, 'w') as out:
        if total_size:
            out.write('%s\t%d\n' % ('size', total_size[0]))

    # update package prefixes list
    with open(os.path.join(conf['cache_dir'], 'pkg-prefixes'), 'w') as out:
        for prefix in SourceMirror(conf['mirror_dir']).pkg_prefixes():
            out.write('%s\n' % prefix)

    # update timestamp
    timestamp_file = os.path.join(conf['cache_dir'], 'last-update')
    with open(timestamp_file, 'w') as out:
        out.write('%s\n' % formatdate())


def finish(conf, session):
    """clean up actions
    """
    update_metadata(conf, session)
    # note: lockfile is removed via atexit, no need to do that explicitly here
    logging.info('finish')


def update(conf, session):
    """do a full update run
    """
    dry = conf['dry_run']

    def extract_new(mirror):
        """step 1: list mirror and extract new packages
        """
        logging.info('add new packages...')
        src_list_path = os.path.join(conf['cache_dir'], 'sources.txt')
        src_list = open(src_list_path + '.new', 'w')
        for pkg in mirror.ls():
            pkgdir = pkg.extraction_dir(conf['sources_dir'])
            if not dbutils.lookup_version(session,
                                          pkg['package'], pkg['version']):
                try:
                    logging.info('add %s...' % pkg)
                    if not dry and 'fs' in conf['passes']:
                        fs_storage.extract_package(pkg, pkgdir)
                    with session.begin_nested():
                        # single db session for package addition and hook
                        # execution: if the hooks fail, the package won't be
                        # added to the db (it will be tried again at next run)
                        if not dry and 'db' in conf['passes']:
                            dbutils.add_package(session, pkg)
                        if not dry and 'hooks' in conf['passes']:
                            notify(conf, 'add-package', session, pkg, pkgdir)
                except:
                    logging.exception('failed to extract %s' % pkg)
            if conf['force_triggers']:
                try:
                    notify_plugins('add-package', session, pkg, pkgdir,
                                   triggers=conf['force_triggers'],
                                   dry=dry)
                except:
                    logging.exception('trigger failure on %s' % pkg)
            src_list.write('%s\t%s\t%s\t%s\t%s\n' %
                           (pkg['package'], pkg['version'], pkg.archive_area(),
                            pkg.dsc_path(), pkgdir))
        src_list.close()
        os.rename(src_list_path + '.new', src_list_path)

    def garbage_collect(mirror):
        """step 2: list db and remove disappeared and expired packages
        """
        logging.info('garbage collection...')
        for version in session.query(Version).all():
            pkg = SourcePackage.from_db_model(version)
            pkg_id = (pkg['package'], pkg['version'])
            pkgdir = pkg.extraction_dir(conf['sources_dir'])
            if not pkg_id in mirror.packages:
                # package is in in Debsources db, but gone from mirror: we
                # might have to garbage collect it (depending on expiry)
                try:
                    expire_days = conf['expire_days']
                    age = None
                    if os.path.exists(pkgdir):
                        age = datetime.now() \
                              - datetime.fromtimestamp(os.path.getctime(pkgdir))
                    if not age or age.days >= expire_days:
                        logging.info("gc %s..." % pkg)
                        if not dry and 'hooks' in conf['passes']:
                            notify(conf, 'rm-package', session, pkg, pkgdir)
                        if not dry and 'fs' in conf['passes']:
                            fs_storage.remove_package(pkg, pkgdir)
                        if not dry and 'db' in conf['passes']:
                            with session.begin_nested():
                                dbutils.rm_package(session, pkg, version)
                    else:
                        logging.debug('not removing %s as it is too young' % pkg)
                except:
                    logging.exception('failed to remove %s' % pkg)
            if conf['force_triggers']:
                try:
                    notify_plugins('rm-package', session, pkg, pkgdir,
                                   triggers=conf['force_triggers'],
                                   dry=dry)
                except:
                    logging.exception('trigger failure on %s' % pkg)

    init(conf)
    logging.info('list mirror packages...')
    mirror = SourceMirror(conf['mirror_dir'])
    extract_new(mirror)
    garbage_collect(mirror)
    finish(conf, session)


if __name__ == '__main__':
    cmdline = argparse.ArgumentParser(description='Debsources updater')
    cmdline.add_argument('--config', '-c', dest='conffile',
                         help='alternate configuration file')
    cmdline.add_argument('--dry-run', '-d', dest='dry',
                         action='store_true',
                         help='enable dry run mode')
    cmdline.add_argument('--pass', '-p',
                         metavar='PASS',
                         action='append',
                         help='only perform a specific update pass (one of: db, fs, hooks, hooks.db, hooks.fs). By default all passes are enabled; the special value "none" disables all passes. Can be specified multiple times. Warning: you will mess up update logic, use at your own risk.',
                         dest='passes')
    cmdline.add_argument('--trigger', '-t',
                         metavar='EVENT/HOOK',
                         action='append',
                         help='force trigger of (Python) HOOK for EVENT. By default all registered hooks are triggered for all changed packages. Event is one of: %s. Hook is one of the available hooks. Can be specified multiple times. Warning: if not used with "--pass none" it might lead to multiple execution of the same hook. E.g.: -t add-package/checksums' % string.join(mainlib.KNOWN_EVENTS, ', '),
                         dest='force_triggers')
    cmdline.add_argument('--verbose', '-v',
                         action='count',
                         help='increase console verbosity')
    args = cmdline.parse_args()

    conf = mainlib.load_configuration(args.conffile)
    # override configuration from cmdline args
    if args.passes:
        if 'none' in args.passes:
            conf['passes'] = set()
        else:
            conf['passes'] = set(args.passes)
    if args.force_triggers:
        conf['force_triggers'] = []
        for trigger in args.force_triggers:
            (event, hook) = trigger.split('/')
            conf['force_triggers'].append((event, hook))
    if args.dry:
        conf['dry_run'] = True

    mainlib.init_logging(conf, mainlib.log_level_of_verbosity(args.verbose))
    logging.debug('loaded configuration from %s' % conf['conffile'])
    (observers, _file_exts)  = mainlib.load_hooks(conf)
    try:
        db = create_engine(conf['db_uri'])
        session = Session(bind=db)
        update(conf, session)
        session.commit()
    except SystemExit:	# exit as requested
        raise
    except:	# store trace in log, then exit
        logging.exception('unhandled exception. Abort')
        sys.exit(2)
