Research
========

Persistence
-----------

With the AQMP backend, tasks are persistent by default (messages are
saved both in-memory and on disk).

http://celery.readthedocs.org/en/latest/internals/reference/celery.backends.amqp.html#celery.backends.amqp.AMQPBackend.Exchange.delivery_mode

By default, if a worker crashes mid-execution, the task will not be
run again. It is possible to enable 'late acks', meaning tasks will be
aknowledged only after a successful execution. Tasks need to be
idempotent for that to work correctly.

 - http://celery.readthedocs.org/en/latest/faq.html#faq-acks-late-vs-retry

 - http://celery.readthedocs.org/en/latest/configuration.html#celery-acks-late



Transactional tasks
-------------------

Celery does not support transactional task queues.

Several libraries try to add the feature:

pyramid_transactional_celery
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

 -> https://pypi.python.org/pypi/pyramid_transactional_celery

Developed for use with pyramid, but does not depend on pyramid.

Uses Zope's transaction library:
https://pypi.python.org/pypi/transaction

Available in debian: python-transaction, depends on
python-zope.interface.

django-transaction-barrier
~~~~~~~~~~~~~~~~~~~~~~~~~~

-> https://libraries.io/pypi/django-transaction-barrier

For django. 


Unit tests 
----------

For unit testing, tasks can easily be made synchronous.

-> CELERY_ALWAYS_EAGER = True

Workflow
--------


Celery has several ways to define workflows:
http://celery.readthedocs.org/en/latest/userguide/canvas.html


Hooks
~~~~~

Hooks can be run as chord[1], i.e. a group of tasks run in parallel,
with a callback that will be executed once all of the tasks have
completed.

By default on celery 3.1+, if one of the tasks fail, the callback will
not be executed[2] (this behavior can be disabled, or enabled on
celery 3.0).

This mean tasks running the hooks can send the results of the plugins
to a callback which will insert those results into the database.

This solution allows:
 
 - running the hooks on machines that don't have access to the
   database
 
 - not importing a package if one of the hooks failed

However, it increases the network overhead. In particular, the ctags
plugin can generate large sets of data (e.g. ~250MB for
chromium-browser, or 100M gziped).

One possible workaround is to pass the data as a local file when the
callback runs on the same machine.

It is possible to run a task on a given worker[3][4]. Determining on
which worker a task is executed should also possible, using
billiard.current_process[5] and sending the id of the current worker
to the subtask.

[1] http://celery.readthedocs.org/en/latest/userguide/canvas.html#chords
[2] http://celery.readthedocs.org/en/latest/userguide/canvas.html#error-handling
[3] http://docs.celeryproject.org/en/latest/configuration.html#celery-worker-direct
[4] http://docs.celeryproject.org/en/latest/internals/reference/celery.utils.html#celery.utils.worker_direct
[5] https://docs.python.org/2/library/multiprocessing.html#multiprocessing.current_process



Implementation details
======================

sqlalchemy session
------------------

The session is defined as a global variable in tasks.py. It might be a
good idea to set it up using a worker signal[1] instead.

Tasks that need to use it must inherit DBTask, which ensures that the
session will be returned to the pool after the execution.

DBTask is currently defined in tasks.py, and reimplements the
'after_return' handler[2].

[1] http://docs.celeryproject.org/en/latest/userguide/tasks.html#handlers
[2] http://celery.readthedocs.org/en/latest/userguide/signals.html#worker-signals



Celery configuration
====================

Result backend
--------------

To use chords, we need to keep a result backend for keeping the results
of tasks and passing them to other tasks. Result backends are disabled by default, and several choices are available[1]:
 
 - sqlalchemy
 - memcached
 - redis
 - rabbitmq
 - ...

[1]
http://celery.readthedocs.org/en/latest/configuration.html#task-result-backend-settings

Dependencies
============

 - python-celery
 - rabbitmq


Running
=======

Worker
------

    bin/debsources-async-celery worker


Updater
-------

    bin/debsources-async-update
